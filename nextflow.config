// Enable Nextflow DSL2
nextflow.enable.dsl=2

// Pipeline metadata
manifest {
    name = 'Bacterial-AMR-Pipeline'
    author = 'Aaryesh Deshpande'
    description = 'Bacterial genome assembly and AMR detection pipeline'
    mainScript = 'main.nf'
    version = '1.0.0'
    nextflowVersion = '>=24.10.0'
}

// Input/Output Parameters
params {
    // Data source selection
    use_sra = false                         // Set to true to use SRA data instead of local files
    
    // Input options - either read files or SRA IDs
    reads = "test_data/*_R{1,2}.fastq.gz"   // Pattern for local paired-end reads
    sra_ids = ""                            // Comma-separated list of SRA IDs (e.g., "SRR10971381,SRR10971382")
    
    // Output directory
    outdir = "results"
    
    // Resource management
    cleanup = true                          // Enables automatic work directory cleanup
    memory = '12 GB'                        // Sets global maximum memory
    cpus = 4                                // Maximum CPUs for any process
    time = '12.h'                           // Maximum runtime for any process
    
    // FASTP parameters (subject to change according to data.... pls change accordingly)
    save_trimmed_reads = true               // Keep trimmed read files
    fastp_qualified_quality = 20            // Minimum quality for a good base
    fastp_unqualified_percent_limit = 40    // Percent of unqualified bases allowed
    fastp_cut_window_size = 4               // Window size for cutting by quality
    fastp_cut_mean_quality = 20             // Mean quality requirement in cutting sliding window
    fastp_min_length = 36                   // Minimum read length after trimming
    
    // SPAdes parameters (similar caution as FASTP)
    spades_mode = "isolate"                 // Mode for SPAdes assembly
    spades_memory = 4
    spades_careful = false 

    // QUAST parameters
    quast_min_contig = 200                  // Minimum contig length for QUAST analysis
    
    // Prodigal parameters
    prodigal_mode = "meta"                  // Genetic code to use for Prodigal
    
    // AMR Finder parameters (similar caution as FASTP... don't wanna sound repetitive)
    amr_organism = false                    // Taxonomy name (e.g., "Escherichia") Set if you know that the organism (which is not the case in this pipeline)
    amr_identity = 0.9                      // Minimum identity threshold
    amr_coverage = 0.9                      // Minimum coverage threshold
}

// Output Organization
workDir = 'work'

// Process configuration (I have used a lot of hardcoded values here, but they can be changed to math calc parameters if needed.. I faced a lot of issues, so I used this for now)
process {
    // Default settings for all processes
    cpus = { check_max(1 * task.attempt, 'cpus') }
    memory = { check_max(4.GB * task.attempt, 'memory') }
    time = { check_max(2.h * task.attempt, 'time') }
    
    // Error handling
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries = 3
    
    // Default publish directory structure
    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].toLowerCase()}" },
        mode: 'copy',
        overwrite: true
    ]
    
    // Process-specific configurations with containers
    withName:GET_SRR {
        container = 'quay.io/biocontainers/sra-tools:3.0.3--h87f3376_0'
        cpus = 4
        memory = '8 GB'
        time = '6.h'
        // Cache downloaded files
        storeDir = { "${params.outdir}/sra_data" }
    }
    
    withName:FASTP {
        container = 'staphb/fastp:0.23.2'
        cpus = 4
        memory = '8 GB'
    }
    
    withName:SPADES {
        container = 'staphb/spades:3.15.5'
        cpus = params.cpus
        memory = params.memory
        time = '24.h'
    }
    
    withName:QUAST {
        container = 'staphb/quast:5.2.0'
        cpus = 2
        memory = '4 GB'
    }
    
    withName:PRODIGAL {
        container = 'quay.io/biocontainers/prodigal:2.6.3--h031d066_6'
        cpus = 2
        memory = '4 GB'
    }
    
    withName:AMR_FINDER {
        container = 'staphb/ncbi-amrfinderplus:4.0.19-2024-12-18.1'
        cpus = 4
        memory = '8 GB'
        time = '4.h'
    }
}

// Define profiles for different execution environments

profiles {
    standard {
        process.executor = 'local'
        docker.enabled = true
        docker.runOptions = '-u $(id -u):$(id -g)'
    }
    
    docker {
        docker.enabled = true
        docker.runOptions = '-u $(id -u):$(id -g)'
        docker.temp = 'auto'
    }
    
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
    }
    
    // High performance cluster profile
    hpc {
        process.executor = 'slurm'
        process.queue = 'standard'
        process.clusterOptions = '--account=project123'
    }
    
    // Add a profile for cloud execution if needed
    aws {
        process.executor = 'awsbatch'
        process.queue = 'nextflow-batch-queue'
        aws.region = 'us-east-1'
        aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
    }
    
    // Testing profile with minimum resources
    test {
        params.reads = "test_data/*_R{1,2}.fastq.gz"
        params.memory = '4 GB'
        params.cpus = 2
    }
}

// Function to check and set maximum values for resources ( I stole this from GitHub, so I don't know how it works, but it does work..lol)
def check_max(obj, type) {
    if (obj == null) return type == 'cpus' ? 1 : type == 'memory' ? '1GB' : '1h'
    
    switch (type) {
        case 'memory':
            try {
                def mem = obj instanceof String ? obj as nextflow.util.MemoryUnit : obj
                return mem.compareTo(params.memory as nextflow.util.MemoryUnit) <= 0 ? 
                    mem : params.memory as nextflow.util.MemoryUnit
            } catch (Exception e) {
                return obj
            }
        
        case 'cpus':
            try {
                def cpuVal = obj instanceof Number ? obj : Integer.parseInt(obj.toString())
                return Math.min(cpuVal, params.cpus as int)
            } catch (Exception e) {
                return Math.min(1, params.cpus as int)
            }
        
        case 'time':
            try {
                def timeVal = obj instanceof nextflow.util.Duration ? obj : obj as nextflow.util.Duration
                return timeVal.compareTo(params.time as nextflow.util.Duration) <= 0 ? 
                    timeVal : params.time as nextflow.util.Duration
            } catch (Exception e) {
                return obj
            }
        
        default:
            return obj
    }
}

// Pipeline report settings
report {
    enabled = true
    file = "${params.outdir}/execution_report.html"
    overwrite = true
}

// Timeline visualization
timeline {
    enabled = true
    file = "${params.outdir}/execution_timeline.html"
    overwrite = true
}

// Execution trace (sometimes trace error can occur, so change as needed)
trace {
    enabled = true
    file = "${params.outdir}/execution_trace.txt"
    fields = 'task_id,hash,native_id,name,status,exit,submit,start,complete,duration,realtime,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
    overwrite = true
}

// Workflow diagram (cute little diagram)
dag {
    enabled = true
    file = "${params.outdir}/pipeline_dag.svg"
    overwrite = true
}